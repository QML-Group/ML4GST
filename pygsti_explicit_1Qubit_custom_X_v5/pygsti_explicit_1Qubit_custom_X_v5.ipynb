{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zd1H8cDcvaHr",
    "outputId": "f39b22da-e568-4310-c94a-93de13ab5e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Google Colab specific code for mounting Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# # Define the directory path on your Google Drive\n",
    "# # Replace 'Your_directory' with the actual directory\n",
    "# directory = '/content/drive/My Drive/Colab Notebooks/ML4GST/'\n",
    "\n",
    "# # Now use this directory for reading and writing data\n",
    "# data_template_filename = directory + \"dataset.txt\"\n",
    "# gst_dir = directory + \"test_gst_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RJyTecyWOVa",
    "outputId": "852b7777-2a72-44cb-8d44-81a04f25f58d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\ULTIMATEWOWEE\\Documents\\ML4GST\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory to the desired path\n",
    "os.chdir(r\"C:\\Users\\ULTIMATEWOWEE\\Documents\\ML4GST\")\n",
    "\n",
    "# Verify that the working directory has been changed\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDzCiN2Ru6ky",
    "outputId": "b076112b-7037-4547-e000-9d17dd4d693a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygsti\n",
      "  Downloading pyGSTi-0.9.11.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from pygsti) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pygsti) (1.10.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from pygsti) (5.15.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pygsti) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pygsti) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pygsti) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->pygsti) (8.2.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly->pygsti) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->pygsti) (1.16.0)\n",
      "Installing collected packages: pygsti\n",
      "Successfully installed pygsti-0.9.11.2\n"
     ]
    }
   ],
   "source": [
    "pip install pygsti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLOeLti-u9tg",
    "outputId": "47bc21b0-1ba7-43cf-cbf0-7c8900b75490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_model: \n",
      " rho0 = FullState with dimension 4\n",
      " 0.71   0   0 0.71\n",
      "\n",
      "\n",
      "Mdefault = UnconstrainedPOVM with effect vectors:\n",
      "0: FullPOVMEffect with dimension 4\n",
      " 0.71   0   0 0.71\n",
      "\n",
      "1: FullPOVMEffect with dimension 4\n",
      " 0.71   0   0-0.71\n",
      "\n",
      "\n",
      "\n",
      "Gi = \n",
      "FullArbitraryOp with shape (4, 4)\n",
      " 1.00   0   0   0\n",
      "   0 1.00   0   0\n",
      "   0   0 1.00   0\n",
      "   0   0   0 1.00\n",
      "\n",
      "\n",
      "Gx = \n",
      "MyXPi2Operator with shape (4, 4)\n",
      " 1.00   0   0   0\n",
      "   0 1.00   0   0\n",
      "   0   0-0.63-0.77\n",
      "   0   0 0.77-0.63\n",
      "\n",
      "\n",
      "Gy = \n",
      "FullArbitraryOp with shape (4, 4)\n",
      " 1.00   0   0   0\n",
      "   0   0   0 1.00\n",
      "   0   0 1.00   0\n",
      "   0-1.00   0   0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ideal_target_model: \n",
      " rho0 = FullState with dimension 4\n",
      " 0.71   0   0 0.71\n",
      "\n",
      "\n",
      "Mdefault = UnconstrainedPOVM with effect vectors:\n",
      "0: FullPOVMEffect with dimension 4\n",
      " 0.71   0   0 0.71\n",
      "\n",
      "1: FullPOVMEffect with dimension 4\n",
      " 0.71   0   0-0.71\n",
      "\n",
      "\n",
      "\n",
      "Gi = \n",
      "FullArbitraryOp with shape (4, 4)\n",
      " 1.00   0   0   0\n",
      "   0 1.00   0   0\n",
      "   0   0 1.00   0\n",
      "   0   0   0 1.00\n",
      "\n",
      "\n",
      "Gx = \n",
      "FullArbitraryOp with shape (4, 4)\n",
      " 1.00   0   0   0\n",
      "   0 1.00   0   0\n",
      "   0   0 0.71-0.71\n",
      "   0   0 0.71 0.71\n",
      "\n",
      "\n",
      "Gy = \n",
      "FullArbitraryOp with shape (4, 4)\n",
      " 1.00   0   0   0\n",
      "   0   0   0 1.00\n",
      "   0   0 1.00   0\n",
      "   0-1.00   0   0\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pygsti\n",
    "import pygsti.algorithms.fiducialselection as fidsel\n",
    "import pygsti.algorithms.germselection as germsel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Pauli Transfer Matrices for the gates\n",
    "# I = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "# X_pi_4 = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, np.cos(np.pi/4), -np.sin(np.pi/4)], [0, 0, np.sin(np.pi/4), np.cos(np.pi/4)]])\n",
    "# Y_pi_2 = np.array([[1, 0, 0, 0], [0, np.cos(np.pi/2), 0, np.sin(np.pi/2)], [0, 0, 1, 0], [0, -np.sin(np.pi/2), 0, np.cos(np.pi/2)]])\n",
    "\n",
    "# Create the explicit model\n",
    "ideal_target_model = pygsti.models.create_explicit_model_from_expressions(\n",
    "    [('Q0',)], ['Gi', 'Gx', 'Gy'],\n",
    "    [\"I(Q0)\", \"X(pi/4,Q0)\", \"Y(pi/2,Q0)\"])\n",
    "\n",
    "class MyXPi2Operator(pygsti.modelmembers.operations.DenseOperator):\n",
    "    def __init__(self):\n",
    "        #initialize with no noise\n",
    "        super(MyXPi2Operator,self).__init__(np.identity(4,'d'), 'pp', \"densitymx\") # this is *super*-operator, so \"densitymx\"\n",
    "        self.from_vector([0.0, 0.1])\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 2 # we have two parameters\n",
    "\n",
    "    def to_vector(self):\n",
    "        return np.array([self.depol_amt, self.over_rotation],'d') #our parameter vector\n",
    "\n",
    "    def from_vector(self, v, close=False, dirty_value=True):\n",
    "        #initialize from parameter vector v\n",
    "        self.depol_amt = v[0]\n",
    "        self.over_rotation = v[1]\n",
    "\n",
    "        # print(f'depol_amt: {self.depol_amt}, over_rotation: {self.over_rotation}')\n",
    "\n",
    "        theta = (np.pi/4 + self.over_rotation)/2\n",
    "        a = 1.0-self.depol_amt\n",
    "        b = a*2*np.cos(theta)*np.sin(theta)\n",
    "        c = a*(np.sin(theta)**2 - np.cos(theta)**2)\n",
    "\n",
    "        # print(f'a: {a}, b: {b}, c: {c}')\n",
    "\n",
    "        # ._ptr is a member of DenseOperator and is a numpy array that is\n",
    "        # the dense Pauli transfer matrix of this operator\n",
    "        # Technical note: use [:,:] instead of direct assignment so id of self._ptr doesn't change\n",
    "        self._ptr[:,:] = np.array([[1,   0,   0,   0],\n",
    "                                  [0,   a,   0,   0],\n",
    "                                  [0,   0,   c,  -b],\n",
    "                                  [0,   0,   b,   c]],'d')\n",
    "        self.dirty = dirty_value  # mark that parameter vector may have changed\n",
    "\n",
    "    def transform(self, S):\n",
    "        # Update self with inverse(S) * self * S (used in gauge optimization)\n",
    "        raise NotImplementedError(\"MyXPi2Operator cannot be transformed!\")\n",
    "\n",
    "import copy\n",
    "target_model = copy.deepcopy(ideal_target_model)\n",
    "target_model.operations[('Gx')] = MyXPi2Operator()\n",
    "print('target_model: \\n', target_model)\n",
    "print('ideal_target_model: \\n', ideal_target_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4rvB8JHcipz",
    "outputId": "0c701123-b036-447b-af62-279e54d5acf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Length Available Fiducial List: 7\n",
      "Length Available Fiducial List Dropped Identities and Duplicates: 7\n",
      "Using GRASP algorithm.\n",
      "Preparation fiducials:\n",
      "['{}', 'Gy', 'GxGx', 'GyGy']\n",
      "Score: 32.0\n",
      "Measurement fiducials:\n",
      "['{}', 'Gy', 'GxGx']\n",
      "Score: 9.999999999999996\n",
      "Initial Length Available Germ List: 196\n",
      "Length Available Germ List After Deduping: 59\n",
      "Length Available Germ List After Dropping Random Fraction: 59\n",
      "Length Available Germ List After Adding Back In Forced Germs: 59\n",
      "Memory estimate of 0.0 GB for all-Jac mode.\n",
      "Memory estimate of 0.0 GB for single-Jac mode.\n",
      "Using greedy algorithm.\n",
      "Constructed germ set:\n",
      "['Gi', 'Gx', 'Gy', 'GxGxGy', 'GiGxGx', 'GiGyGx', 'GiGyGxGxGyGy', 'GiGyGyGyGxGx', 'GxGxGyGxGyGy', 'GiGxGyGyGyGx']\n",
      "Score: major=-34.0 minor=711.6500383006758, N: 34\n"
     ]
    }
   ],
   "source": [
    "# Automatic selection of fiducials and germs using \"laissez-faire\" method\n",
    "prepFiducials, measFiducials = fidsel.find_fiducials(ideal_target_model)\n",
    "germs = germsel.find_germs(ideal_target_model, seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dtc8CpOEjL9R",
    "outputId": "8756bd8b-a691-4584-dc0b-cf94e1fa20a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepFiducials: [Circuit({}), Circuit(Gy), Circuit(GxGx), Circuit(GyGy)] \n",
      " measFiducials: [Circuit({}), Circuit(Gy), Circuit(GxGx)] \n",
      " germs: [Circuit(Gi), Circuit(Gx), Circuit(Gy), Circuit(GxGxGy), Circuit(GiGxGx), Circuit(GiGyGx), Circuit(GiGyGxGxGyGy), Circuit(GiGyGyGyGxGx), Circuit(GxGxGyGxGyGy), Circuit(GiGxGyGyGyGx)]\n"
     ]
    }
   ],
   "source": [
    "print(f'prepFiducials: {prepFiducials} \\n measFiducials: {measFiducials} \\n germs: {germs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uI80q6AIip7Z"
   },
   "outputs": [],
   "source": [
    "# Generate a list of circuits using the long-sequence gate set tomography (LSGST) method\n",
    "maxLengths = [2**n for n in range(5)]\n",
    "\n",
    "listOfExperiments = pygsti.circuits.create_lsgst_circuits(\n",
    "    target_model, prepFiducials, measFiducials, germs, maxLengths)\n",
    "\n",
    "# Simulate the probability outcomes of these circuits\n",
    "ds = pygsti.data.simulate_data(target_model, listOfExperiments, num_samples=1000,\n",
    "                                            sample_error=\"binomial\", seed=1234)\n",
    "# print(ds)\n",
    "\n",
    "pygsti.io.write_dataset(\"Custom_1Q_XYI_dataset_abc.txt\", ds, outcome_label_order=['0','1'])\n",
    "\n",
    "# Convert the probabilities to a DataFrame and save to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6XTVMibkMAOZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Lambda\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the sorted data directly from the modified CSV\n",
    "df_sorted = pd.read_csv('Sorted_Encoded_Padded_Probabilities.csv')\n",
    "\n",
    "def prepare_data(df_part):\n",
    "    # Extracting features and labels\n",
    "    X = df_part['Padded'].apply(lambda x: [int(xi) for xi in x.strip('[]').split()]).to_list()\n",
    "    y = df_part[['Prob1', 'Prob2']].values\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = prepare_data(df_sorted)\n",
    "\n",
    "# Create new input data\n",
    "X_new = [X, y]\n",
    "\n",
    "# Split the original input (X[0]) and target labels (y) into training and test sets\n",
    "X_train_0, X_test_0, y_train, y_test = train_test_split(X_new[0], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Manually combine the split y labels into the X data\n",
    "X_train = [np.array(X_train_0), np.array(y_train)]\n",
    "X_test = [np.array(X_test_0), np.array(y_test)]\n",
    "\n",
    "# Convert y data to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss1P_yEzuKGa",
    "outputId": "6199d20f-8891-4233-92f3-5354befe8b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 0, 0, 0],\n",
       "       [2, 1, 0, ..., 0, 0, 0],\n",
       "       [3, 2, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [2, 3, 2, ..., 0, 0, 0],\n",
       "       [2, 2, 3, ..., 0, 0, 0],\n",
       "       [2, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmZRwn4eppiP",
    "outputId": "1ed37778-bdb8-42e1-9430-64e1b630affc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHAjtNHVuG-R",
    "outputId": "6be485e2-ec20-4707-e0db-e20efb7eb40d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49 , 0.51 ],\n",
       "       [0.492, 0.508],\n",
       "       [0.526, 0.474],\n",
       "       [0.227, 0.773],\n",
       "       [0.   , 1.   ],\n",
       "       [0.922, 0.078],\n",
       "       [0.513, 0.487],\n",
       "       [0.519, 0.481],\n",
       "       [0.501, 0.499],\n",
       "       [0.715, 0.285],\n",
       "       [0.474, 0.526],\n",
       "       [0.969, 0.031],\n",
       "       [0.41 , 0.59 ],\n",
       "       [0.508, 0.492],\n",
       "       [0.519, 0.481],\n",
       "       [0.586, 0.414],\n",
       "       [0.95 , 0.05 ],\n",
       "       [0.498, 0.502],\n",
       "       [0.491, 0.509],\n",
       "       [0.644, 0.356],\n",
       "       [0.475, 0.525],\n",
       "       [0.491, 0.509],\n",
       "       [0.594, 0.406],\n",
       "       [0.294, 0.706],\n",
       "       [0.668, 0.332],\n",
       "       [1.   , 0.   ],\n",
       "       [0.525, 0.475],\n",
       "       [0.5  , 0.5  ],\n",
       "       [0.403, 0.597],\n",
       "       [0.   , 1.   ],\n",
       "       [0.501, 0.499],\n",
       "       [0.418, 0.582],\n",
       "       [0.511, 0.489],\n",
       "       [0.323, 0.677],\n",
       "       [0.   , 1.   ],\n",
       "       [0.383, 0.617],\n",
       "       [0.037, 0.963],\n",
       "       [0.983, 0.017],\n",
       "       [0.821, 0.179],\n",
       "       [0.036, 0.964],\n",
       "       [1.   , 0.   ],\n",
       "       [0.052, 0.948],\n",
       "       [0.486, 0.514],\n",
       "       [0.173, 0.827],\n",
       "       [0.466, 0.534],\n",
       "       [0.509, 0.491],\n",
       "       [0.103, 0.897],\n",
       "       [0.287, 0.713],\n",
       "       [0.835, 0.165],\n",
       "       [0.   , 1.   ],\n",
       "       [0.494, 0.506],\n",
       "       [0.894, 0.106],\n",
       "       [0.   , 1.   ],\n",
       "       [0.01 , 0.99 ],\n",
       "       [0.525, 0.475],\n",
       "       [0.485, 0.515],\n",
       "       [0.489, 0.511],\n",
       "       [0.579, 0.421],\n",
       "       [0.429, 0.571],\n",
       "       [0.48 , 0.52 ],\n",
       "       [0.481, 0.519],\n",
       "       [0.554, 0.446],\n",
       "       [0.493, 0.507],\n",
       "       [0.593, 0.407],\n",
       "       [0.937, 0.063],\n",
       "       [0.492, 0.508],\n",
       "       [0.034, 0.966],\n",
       "       [0.931, 0.069],\n",
       "       [1.   , 0.   ],\n",
       "       [0.754, 0.246],\n",
       "       [0.38 , 0.62 ],\n",
       "       [0.516, 0.484],\n",
       "       [0.386, 0.614],\n",
       "       [0.384, 0.616],\n",
       "       [0.512, 0.488],\n",
       "       [0.893, 0.107],\n",
       "       [0.517, 0.483],\n",
       "       [0.116, 0.884],\n",
       "       [0.346, 0.654],\n",
       "       [0.521, 0.479],\n",
       "       [0.778, 0.222],\n",
       "       [0.402, 0.598],\n",
       "       [0.396, 0.604],\n",
       "       [0.388, 0.612],\n",
       "       [0.326, 0.674],\n",
       "       [0.017, 0.983],\n",
       "       [0.504, 0.496],\n",
       "       [0.972, 0.028],\n",
       "       [0.271, 0.729],\n",
       "       [0.497, 0.503],\n",
       "       [0.517, 0.483],\n",
       "       [0.476, 0.524],\n",
       "       [0.829, 0.171],\n",
       "       [0.785, 0.215],\n",
       "       [0.602, 0.398],\n",
       "       [0.486, 0.514],\n",
       "       [0.598, 0.402],\n",
       "       [0.818, 0.182],\n",
       "       [0.51 , 0.49 ],\n",
       "       [0.398, 0.602],\n",
       "       [0.87 , 0.13 ],\n",
       "       [0.667, 0.333],\n",
       "       [0.533, 0.467],\n",
       "       [0.406, 0.594],\n",
       "       [0.606, 0.394],\n",
       "       [0.684, 0.316],\n",
       "       [0.48 , 0.52 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.34 , 0.66 ],\n",
       "       [0.04 , 0.96 ],\n",
       "       [0.491, 0.509],\n",
       "       [1.   , 0.   ],\n",
       "       [0.2  , 0.8  ],\n",
       "       [0.406, 0.594],\n",
       "       [0.67 , 0.33 ],\n",
       "       [0.523, 0.477],\n",
       "       [0.   , 1.   ],\n",
       "       [0.421, 0.579],\n",
       "       [0.79 , 0.21 ],\n",
       "       [0.581, 0.419],\n",
       "       [1.   , 0.   ],\n",
       "       [0.593, 0.407],\n",
       "       [1.   , 0.   ],\n",
       "       [0.52 , 0.48 ],\n",
       "       [0.124, 0.876],\n",
       "       [0.481, 0.519],\n",
       "       [0.532, 0.468],\n",
       "       [0.67 , 0.33 ],\n",
       "       [0.409, 0.591],\n",
       "       [0.496, 0.504],\n",
       "       [0.   , 1.   ],\n",
       "       [0.967, 0.033],\n",
       "       [0.081, 0.919],\n",
       "       [0.427, 0.573],\n",
       "       [0.342, 0.658],\n",
       "       [0.189, 0.811],\n",
       "       [0.39 , 0.61 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.484, 0.516],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.512, 0.488],\n",
       "       [0.409, 0.591],\n",
       "       [0.529, 0.471],\n",
       "       [0.322, 0.678],\n",
       "       [0.483, 0.517],\n",
       "       [1.   , 0.   ],\n",
       "       [0.716, 0.284],\n",
       "       [0.49 , 0.51 ],\n",
       "       [0.08 , 0.92 ],\n",
       "       [0.321, 0.679],\n",
       "       [0.513, 0.487],\n",
       "       [1.   , 0.   ],\n",
       "       [0.184, 0.816],\n",
       "       [0.435, 0.565],\n",
       "       [0.338, 0.662],\n",
       "       [1.   , 0.   ],\n",
       "       [0.472, 0.528],\n",
       "       [0.875, 0.125],\n",
       "       [0.494, 0.506],\n",
       "       [1.   , 0.   ],\n",
       "       [0.485, 0.515],\n",
       "       [0.007, 0.993],\n",
       "       [0.412, 0.588],\n",
       "       [0.919, 0.081],\n",
       "       [0.506, 0.494],\n",
       "       [0.631, 0.369],\n",
       "       [0.398, 0.602],\n",
       "       [0.993, 0.007],\n",
       "       [0.036, 0.964],\n",
       "       [0.496, 0.504],\n",
       "       [0.49 , 0.51 ],\n",
       "       [0.03 , 0.97 ],\n",
       "       [0.47 , 0.53 ],\n",
       "       [0.042, 0.958],\n",
       "       [0.517, 0.483],\n",
       "       [0.509, 0.491],\n",
       "       [0.223, 0.777],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.484, 0.516],\n",
       "       [0.917, 0.083],\n",
       "       [0.   , 1.   ],\n",
       "       [0.983, 0.017],\n",
       "       [0.941, 0.059],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.04 , 0.96 ],\n",
       "       [0.877, 0.123],\n",
       "       [0.03 , 0.97 ],\n",
       "       [0.32 , 0.68 ],\n",
       "       [0.499, 0.501],\n",
       "       [0.039, 0.961],\n",
       "       [0.5  , 0.5  ],\n",
       "       [0.067, 0.933],\n",
       "       [0.405, 0.595],\n",
       "       [0.502, 0.498],\n",
       "       [0.815, 0.185],\n",
       "       [0.58 , 0.42 ],\n",
       "       [0.48 , 0.52 ],\n",
       "       [0.395, 0.605],\n",
       "       [1.   , 0.   ],\n",
       "       [0.483, 0.517],\n",
       "       [0.508, 0.492],\n",
       "       [0.431, 0.569],\n",
       "       [0.   , 1.   ],\n",
       "       [0.525, 0.475],\n",
       "       [0.263, 0.737],\n",
       "       [0.961, 0.039],\n",
       "       [0.489, 0.511],\n",
       "       [0.089, 0.911],\n",
       "       [0.782, 0.218],\n",
       "       [0.861, 0.139],\n",
       "       [0.172, 0.828],\n",
       "       [0.504, 0.496],\n",
       "       [0.49 , 0.51 ],\n",
       "       [0.486, 0.514],\n",
       "       [0.116, 0.884],\n",
       "       [0.49 , 0.51 ],\n",
       "       [0.516, 0.484],\n",
       "       [0.196, 0.804],\n",
       "       [0.504, 0.496],\n",
       "       [0.788, 0.212],\n",
       "       [0.   , 1.   ],\n",
       "       [0.813, 0.187],\n",
       "       [0.374, 0.626],\n",
       "       [0.   , 1.   ],\n",
       "       [0.511, 0.489],\n",
       "       [0.999, 0.001],\n",
       "       [0.   , 1.   ],\n",
       "       [0.523, 0.477],\n",
       "       [0.   , 1.   ],\n",
       "       [0.499, 0.501],\n",
       "       [0.   , 1.   ],\n",
       "       [0.028, 0.972],\n",
       "       [0.974, 0.026],\n",
       "       [0.567, 0.433],\n",
       "       [0.376, 0.624],\n",
       "       [0.495, 0.505],\n",
       "       [0.52 , 0.48 ],\n",
       "       [0.329, 0.671],\n",
       "       [0.7  , 0.3  ],\n",
       "       [0.713, 0.287],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.651, 0.349],\n",
       "       [0.54 , 0.46 ],\n",
       "       [0.017, 0.983],\n",
       "       [0.986, 0.014],\n",
       "       [0.398, 0.602],\n",
       "       [0.492, 0.508],\n",
       "       [0.476, 0.524],\n",
       "       [0.178, 0.822],\n",
       "       [0.675, 0.325],\n",
       "       [0.001, 0.999],\n",
       "       [0.123, 0.877],\n",
       "       [0.   , 1.   ],\n",
       "       [0.04 , 0.96 ],\n",
       "       [0.518, 0.482],\n",
       "       [0.872, 0.128],\n",
       "       [0.81 , 0.19 ],\n",
       "       [0.607, 0.393],\n",
       "       [0.5  , 0.5  ],\n",
       "       [0.499, 0.501],\n",
       "       [0.498, 0.502],\n",
       "       [0.043, 0.957],\n",
       "       [0.502, 0.498],\n",
       "       [0.375, 0.625],\n",
       "       [0.499, 0.501],\n",
       "       [0.39 , 0.61 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.217, 0.783]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKV11cBruTr6",
    "outputId": "809134d7-9525-4f66-c81d-0184302a7118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49, 0.51])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rSc7GUbxdydS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, decay_steps, decay_rate):\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        return self.initial_learning_rate / (1 + self.decay_rate * step / self.decay_steps)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"decay_steps\": self.decay_steps,\n",
    "            \"decay_rate\": self.decay_rate\n",
    "        }\n",
    "\n",
    "\n",
    "# class CustomLearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "#   def __init__(self, initial_learning_rate):\n",
    "#     self.initial_learning_rate = initial_learning_rate\n",
    "\n",
    "#   def __call__(self, step):\n",
    "#      return self.initial_learning_rate / (step + 1)\n",
    "\n",
    "# Define model\n",
    "# model = Sequential([\n",
    "#     Dense(20, activation='relu', input_shape=(len(X_train[0]),)),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(2, activation='sigmoid'),  # Sigmoid function outputs in the range [0, 1]\n",
    "# ])\n",
    "# model = Sequential([\n",
    "#     Dense(20, activation='relu', input_shape=(len(X_train[0]),)),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(2, activation='relu'),\n",
    "# ])\n",
    "\n",
    "# # Scale model output to range [0, 2pi]\n",
    "# scaling_layer = Lambda(lambda x: x * 2 * math.pi)\n",
    "# model.add(scaling_layer)\n",
    "\n",
    "# Define model architecture\n",
    "input_X = Input(shape=(len(X_train[0][0]),), name='input_X')\n",
    "input_y = Input(shape=(len(X_train[1][0]),), name='input_y')\n",
    "\n",
    "# Original branch\n",
    "x1 = Dense(20, activation='relu')(input_X)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "# New branch\n",
    "x2 = Dense(2, activation='relu')(input_y)\n",
    "x2 = Dense(64, activation='relu')(x2)\n",
    "\n",
    "# Concatenate branches\n",
    "merged = Concatenate()([x1, x2])\n",
    "merged = Dense(64, activation='relu')(merged)\n",
    "merged = Dense(2, activation='relu')(merged)\n",
    "\n",
    "# Create and compile model\n",
    "model = Model(inputs=[input_X, input_y], outputs=merged)\n",
    "\n",
    "# Compile model\n",
    "\n",
    "initial_learning_rate = 1e-5\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.01\n",
    "lr_schedule = CustomLearningRateScheduler(initial_learning_rate, decay_steps, decay_rate)\n",
    "# lr_schedule = CustomLearningRateScheduler(initial_learning_rate)\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Custom X gate\n",
    "def custom_X(depol_amt, over_rotation):\n",
    "\n",
    "  # print(f'depol_amt: {self.depol_amt}, over_rotation: {self.over_rotation}')\n",
    "\n",
    "  theta = (math.pi/4 + over_rotation)/2\n",
    "  a = 1.0-depol_amt\n",
    "  b = a*2*tf.math.cos(theta)*tf.math.sin(theta)\n",
    "  c = a*(tf.math.sin(theta)**2 - tf.math.cos(theta)**2)\n",
    "\n",
    "  # print(f'a: {a}, b: {b}, c: {c}')\n",
    "\n",
    "  # ._ptr is a member of DenseOperator and is a numpy array that is\n",
    "  # the dense Pauli transfer matrix of this operator\n",
    "  # Technical note: use [:,:] instead of direct assignment so id of self._ptr doesn't change\n",
    "  custom_X_arr = tf.convert_to_tensor([[1,   0,   0,   0],\n",
    "                            [0,   a,   0,   0],\n",
    "                            [0,   0,   c,  -b],\n",
    "                            [0,   0,   b,   c]], dtype=tf.float32)\n",
    "\n",
    "  return custom_X_arr\n",
    "\n",
    "\n",
    "# Define gate application function\n",
    "def apply_gate(state, depol_amt, over_rotation, label):\n",
    "    # Construct arrays using NumPy\n",
    "    # Define gates in PTM form\n",
    "    I_np = np.array([[1, 0, 0, 0],\n",
    "                    [0, 1, 0, 0],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0, 1]], dtype=np.float32)  #Gi\n",
    "\n",
    "    Y_pi_2_np = np.array([[1, 0, 0, 0],\n",
    "                          [0, np.cos(np.pi/2), 0, np.sin(np.pi/2)],\n",
    "                          [0, 0, 1, 0],\n",
    "                          [0, -np.sin(np.pi/2), 0, np.cos(np.pi/2)]], dtype=np.float32) #Gy\n",
    "\n",
    "    # Normalized State corresponding to |0⟩ in Pauli basis\n",
    "    # state_np = np.array([1/np.sqrt(2), 0, 0, 1/np.sqrt(2)], dtype=np.float32)\n",
    "\n",
    "    # Convert NumPy arrays to TensorFlow tensors\n",
    "    I = tf.convert_to_tensor(I_np)\n",
    "    Y_pi_2 = tf.convert_to_tensor(Y_pi_2_np)\n",
    "    # state = tf.convert_to_tensor(state_np)\n",
    "\n",
    "    # X_theta = tf.convert_to_tensor([[1, 0, 0, 0], [0, tf.math.cos(theta_value), 0, tf.math.sin(theta_value)],\n",
    "    #                        [0, 0, 1, 0], [0, -tf.math.sin(theta_value), 0, tf.math.cos(theta_value)]], dtype=tf.float32)  # Gx\n",
    "\n",
    "    X_theta = custom_X(depol_amt, over_rotation)\n",
    "    # print('current label: ', label)\n",
    "\n",
    "    if label == 1:\n",
    "        return tf.linalg.matmul(X_theta, tf.reshape(state, [-1, 1]))\n",
    "    elif label == 2:\n",
    "        return tf.linalg.matmul(Y_pi_2, tf.reshape(state, [-1, 1]))\n",
    "    elif label == 3:\n",
    "        return tf.linalg.matmul(I, tf.reshape(state, [-1, 1]))\n",
    "    else:\n",
    "        return state  # If label is 0, don't apply any gate\n",
    "\n",
    "\n",
    "# def apply_gate_sequence(single_gate_sequence):\n",
    "#     # Initialize state in Pauli basis\n",
    "#     state = tf.convert_to_tensor([1/np.sqrt(2), 0, 0, 1/np.sqrt(2)], dtype=tf.float32)\n",
    "\n",
    "#   # Apply each gate in the sequence\n",
    "#     # print('model(single_gate_sequence[tf.newaxis, :]) ->', model(single_gate_sequence[tf.newaxis, :]))\n",
    "#     depol_amt, over_rotation = tf.squeeze(model(single_gate_sequence[tf.newaxis, :])) # Predict depolar_error, over_rotation for the current gate sequence\n",
    "#     # print('theta_value: ', theta_value)\n",
    "#     # depol_amt = tf.clip_by_value(tf.squeeze(depol_amt), 0, 0.1)\n",
    "#     # over_rotation = tf.clip_by_value(tf.squeeze(over_rotation), 0, 0.1)\n",
    "#     # print(f\"depol_amt: {depol_amt}, over_rotation: {over_rotation}\")\n",
    "#     # print('squeezed theta_value: ', theta_value)\n",
    "#     for i in range(tf.shape(single_gate_sequence)[0]):\n",
    "#       if single_gate_sequence[i] == 0:\n",
    "#         break\n",
    "#       # print('tf.shape(single_gate_sequence): ', tf.shape(single_gate_sequence))\n",
    "#       # print('tf.shape(single_gate_sequence[0]): ', tf.shape(single_gate_sequence)[0])\n",
    "#       # print('single_gate_sequence[i]: ', single_gate_sequence[i])\n",
    "#       state = apply_gate(state, depol_amt, over_rotation, single_gate_sequence[i])\n",
    "#       # print('current state: ', state)\n",
    "\n",
    "#     return state\n",
    "\n",
    "def apply_gate_sequence(single_gate_sequence, single_y_label):\n",
    "    # Initialize state in Pauli basis\n",
    "    state = tf.convert_to_tensor([1/np.sqrt(2), 0, 0, 1/np.sqrt(2)], dtype=tf.float32)\n",
    "\n",
    "    # print(\"Shape of single_gate_sequence:\", tf.shape(single_gate_sequence))\n",
    "    # print(\"Shape of single_y_label:\", tf.shape(single_y_label))\n",
    "    # print(\"Shape of model input single_gate_sequence:\", tf.shape(single_gate_sequence[tf.newaxis, :]))\n",
    "    # print(\"Shape of model input single_gate_sequence:\", tf.shape(single_y_label[tf.newaxis, :]))\n",
    "\n",
    "\n",
    "    # Apply each gate in the sequence\n",
    "    depol_amt, over_rotation = tf.squeeze(model([single_gate_sequence[tf.newaxis, :], single_y_label[tf.newaxis, :]])) # Predict depolar_error, over_rotation for the current gate sequence\n",
    "\n",
    "    for i in range(tf.shape(single_gate_sequence)[0]):\n",
    "        if single_gate_sequence[i] == 0:\n",
    "            break\n",
    "        state = apply_gate(state, depol_amt, over_rotation, single_gate_sequence[i])\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def compute_probabilities(ptm_vector):\n",
    "    # PTM representations for |0> and |1> states\n",
    "    ptm_0 = tf.constant([1, 0, 0, 1], dtype=tf.float32)\n",
    "    ptm_1 = tf.constant([1, 0, 0, -1], dtype=tf.float32)\n",
    "    # ptm_0 = tf.convert_to_tensor([1, 0, 0, 1], dtype=tf.float32)\n",
    "    # ptm_1 = tf.convert_to_tensor([1, 0, 0, -1], dtype=tf.float32)\n",
    "\n",
    "    # Normalize the vectors\n",
    "    ptm_vector = tf.squeeze(tf.linalg.l2_normalize(ptm_vector))\n",
    "    ptm_0 = tf.linalg.l2_normalize(ptm_0)\n",
    "    ptm_1 = tf.linalg.l2_normalize(ptm_1)\n",
    "\n",
    "    # Compute dot products\n",
    "    prob_0 = tf.tensordot(ptm_vector, ptm_0, axes=1)\n",
    "    prob_1 = tf.tensordot(ptm_vector, ptm_1, axes=1)\n",
    "\n",
    "    return tf.stack([prob_0, prob_1])\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = MeanSquaredError()\n",
    "\n",
    "# Define training loop\n",
    "# def train_step(X, y):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#       batched_final_states = []\n",
    "#       batched_probabilities = []\n",
    "\n",
    "#       # Process each sequence in the batch individually\n",
    "#       for i in range(tf.shape(X)[0]):\n",
    "#           single_sequence = tf.gather(X, i, axis=0)\n",
    "#           final_state = apply_gate_sequence(single_sequence)\n",
    "#           probabilities = compute_probabilities(final_state)\n",
    "#           batched_final_states.append(final_state)\n",
    "#           # print('batched_final_states: ', batched_final_states)\n",
    "#           batched_probabilities.append(probabilities)\n",
    "#           # print('batched_probabilities: ', batched_probabilities)\n",
    "\n",
    "#       batched_final_states = tf.stack(batched_final_states)\n",
    "#       # print('batched_final_states: ', batched_final_states)\n",
    "#       # print('batched_final_states.shape: ', batched_final_states.shape)\n",
    "#       batched_probabilities = tf.stack(batched_probabilities)\n",
    "#       # print('batched_probabilities: ', batched_probabilities)\n",
    "#       # print('batched_probabilities.shape: ', batched_probabilities.shape)\n",
    "\n",
    "\n",
    "#       loss = loss_fn(y, batched_probabilities)\n",
    "#       # print('loss: ', loss)\n",
    "\n",
    "#     grads = tape.gradient(loss, model.trainable_weights)\n",
    "#     optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "#     return loss\n",
    "\n",
    "def train_step(X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        batched_final_states = []\n",
    "        batched_probabilities = []\n",
    "\n",
    "        # print(\"Shape of X[0]:\", tf.shape(X[0]))\n",
    "        # print(\"Shape of X[1]:\", tf.shape(X[1]))\n",
    "        # print(\"Shape of y:\", tf.shape(y))\n",
    "\n",
    "        # Process each sequence in the batch individually\n",
    "        # print('tf.shape(X[0])[0]:', tf.shape(X[0])[0])\n",
    "        for i in range(tf.shape(X[0])[0]):\n",
    "            single_sequence = tf.gather(X[0], i, axis=0)\n",
    "            single_y_label = tf.gather(X[1], i, axis=0)\n",
    "            final_state = apply_gate_sequence(single_sequence, single_y_label)\n",
    "            probabilities = compute_probabilities(final_state)\n",
    "            batched_final_states.append(final_state)\n",
    "            batched_probabilities.append(probabilities)\n",
    "\n",
    "        batched_final_states = tf.stack(batched_final_states)\n",
    "        batched_probabilities = tf.stack(batched_probabilities)\n",
    "\n",
    "        loss = loss_fn(y, batched_probabilities)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Define validation loop (similar to training loop but without gradients)\n",
    "# def validate_step(X, y, print_results = False):\n",
    "#     batched_final_states = []\n",
    "#     batched_probabilities = []\n",
    "#     # batched_thetas = []\n",
    "#     batched_errors = []\n",
    "\n",
    "#     for i in range(tf.shape(X)[0]):\n",
    "#         single_sequence = tf.gather(X, i, axis=0)\n",
    "#         final_state = apply_gate_sequence(single_sequence)\n",
    "#         probabilities = compute_probabilities(final_state)\n",
    "#         batched_final_states.append(final_state)\n",
    "#         batched_probabilities.append(probabilities)\n",
    "#         if print_results == True:\n",
    "#             theta_value = tf.squeeze(model(single_sequence[tf.newaxis, :])) # Predict theta for the current gate\n",
    "#             depol_amt, over_rotation = tf.squeeze(model(single_sequence[tf.newaxis, :])) # Predict depolar_error, over_rotation for the current gate sequence\n",
    "#             # batched_thetas.append(theta_value)\n",
    "#             batched_errors.append(tf.stack([depol_amt, over_rotation]))\n",
    "\n",
    "\n",
    "#     batched_final_states = tf.stack(batched_final_states)\n",
    "#     batched_probabilities = tf.stack(batched_probabilities)\n",
    "#     loss = loss_fn(y, batched_probabilities)\n",
    "#     if print_results == True:\n",
    "#       # print('batched_thetas: ', batched_thetas)\n",
    "#       print('batched_errors: ', batched_errors)\n",
    "#     return loss\n",
    "\n",
    "def validate_step(X, y, print_results = False):\n",
    "    batched_final_states = []\n",
    "    batched_probabilities = []\n",
    "    batched_errors = []\n",
    "\n",
    "    for i in range(tf.shape(X[0])[0]):\n",
    "        single_sequence = tf.gather(X[0], i, axis=0)\n",
    "        single_y_label = tf.gather(X[1], i, axis=0)\n",
    "        final_state = apply_gate_sequence(single_sequence, single_y_label)\n",
    "        probabilities = compute_probabilities(final_state)\n",
    "        batched_final_states.append(final_state)\n",
    "        batched_probabilities.append(probabilities)\n",
    "        if print_results == True:\n",
    "            depol_amt, over_rotation = tf.squeeze(model([single_sequence[tf.newaxis, :], single_y_label[tf.newaxis, :]])) # Predict depolar_error, over_rotation for the current gate sequence\n",
    "            batched_errors.append(tf.stack([depol_amt, over_rotation]))\n",
    "\n",
    "    batched_final_states = tf.stack(batched_final_states)\n",
    "    batched_probabilities = tf.stack(batched_probabilities)\n",
    "    loss = loss_fn(y, batched_probabilities)\n",
    "    if print_results == True:\n",
    "        print('batched_errors: ', batched_errors)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mUZNtlhbiL7n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory to save the model and weights\n",
    "model_save_dir = \"saved_models\"\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7buJL9YyU-b",
    "outputId": "0454bbd2-e940-40f6-cb11-08c353dd8401",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part: 1/3, Epoch: 1/100, Total Epochs: 1, Train Loss: 0.006847244221717119, Validation Loss: 0.04055959731340408\n",
      "Part: 1/3, Epoch: 2/100, Total Epochs: 2, Train Loss: 0.0066878520883619785, Validation Loss: 0.04014233872294426\n",
      "Part: 1/3, Epoch: 3/100, Total Epochs: 3, Train Loss: 0.006532345898449421, Validation Loss: 0.03972002863883972\n",
      "Part: 1/3, Epoch: 4/100, Total Epochs: 4, Train Loss: 0.006378372199833393, Validation Loss: 0.039296954870224\n",
      "Part: 1/3, Epoch: 5/100, Total Epochs: 5, Train Loss: 0.006226875353604555, Validation Loss: 0.038875650614500046\n",
      "Part: 1/3, Epoch: 6/100, Total Epochs: 6, Train Loss: 0.0060785380192101, Validation Loss: 0.038455426692962646\n",
      "Part: 1/3, Epoch: 7/100, Total Epochs: 7, Train Loss: 0.00593337370082736, Validation Loss: 0.038037050515413284\n",
      "Part: 1/3, Epoch: 8/100, Total Epochs: 8, Train Loss: 0.0057915495708584785, Validation Loss: 0.03762226179242134\n",
      "Part: 1/3, Epoch: 9/100, Total Epochs: 9, Train Loss: 0.005653177388012409, Validation Loss: 0.0372113361954689\n",
      "Part: 1/3, Epoch: 10/100, Total Epochs: 10, Train Loss: 0.005518263205885887, Validation Loss: 0.03680441901087761\n",
      "Part: 1/3, Epoch: 11/100, Total Epochs: 11, Train Loss: 0.005387037061154842, Validation Loss: 0.036401938647031784\n",
      "Part: 1/3, Epoch: 12/100, Total Epochs: 12, Train Loss: 0.005259817931801081, Validation Loss: 0.03600388765335083\n",
      "Part: 1/3, Epoch: 13/100, Total Epochs: 13, Train Loss: 0.0051361629739403725, Validation Loss: 0.0356108620762825\n",
      "Part: 1/3, Epoch: 14/100, Total Epochs: 14, Train Loss: 0.005015915725380182, Validation Loss: 0.03522321581840515\n",
      "Part: 1/3, Epoch: 15/100, Total Epochs: 15, Train Loss: 0.0048990012146532536, Validation Loss: 0.03484064340591431\n",
      "Part: 1/3, Epoch: 16/100, Total Epochs: 16, Train Loss: 0.004785442259162664, Validation Loss: 0.03446332365274429\n",
      "Part: 1/3, Epoch: 17/100, Total Epochs: 17, Train Loss: 0.00467519648373127, Validation Loss: 0.03409142047166824\n",
      "Part: 1/3, Epoch: 18/100, Total Epochs: 18, Train Loss: 0.004568177275359631, Validation Loss: 0.03372523933649063\n",
      "Part: 1/3, Epoch: 19/100, Total Epochs: 19, Train Loss: 0.004464316181838512, Validation Loss: 0.03336479887366295\n",
      "Part: 1/3, Epoch: 20/100, Total Epochs: 20, Train Loss: 0.004363548941910267, Validation Loss: 0.033009469509124756\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_20\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 20\n",
      "Part: 1/3, Epoch: 21/100, Total Epochs: 21, Train Loss: 0.00426583644002676, Validation Loss: 0.03265976905822754\n",
      "Part: 1/3, Epoch: 22/100, Total Epochs: 22, Train Loss: 0.00417111674323678, Validation Loss: 0.032315876334905624\n",
      "Part: 1/3, Epoch: 23/100, Total Epochs: 23, Train Loss: 0.004079383797943592, Validation Loss: 0.031977564096450806\n",
      "Part: 1/3, Epoch: 24/100, Total Epochs: 24, Train Loss: 0.003990435507148504, Validation Loss: 0.03164414316415787\n",
      "Part: 1/3, Epoch: 25/100, Total Epochs: 25, Train Loss: 0.003903804812580347, Validation Loss: 0.03131583705544472\n",
      "Part: 1/3, Epoch: 26/100, Total Epochs: 26, Train Loss: 0.0038198865950107574, Validation Loss: 0.03099317103624344\n",
      "Part: 1/3, Epoch: 27/100, Total Epochs: 27, Train Loss: 0.0037385886535048485, Validation Loss: 0.030676137655973434\n",
      "Part: 1/3, Epoch: 28/100, Total Epochs: 28, Train Loss: 0.003659907728433609, Validation Loss: 0.030364718288183212\n",
      "Part: 1/3, Epoch: 29/100, Total Epochs: 29, Train Loss: 0.00358367501758039, Validation Loss: 0.03005879372358322\n",
      "Part: 1/3, Epoch: 30/100, Total Epochs: 30, Train Loss: 0.0035097382497042418, Validation Loss: 0.029758330434560776\n",
      "Part: 1/3, Epoch: 31/100, Total Epochs: 31, Train Loss: 0.003438143525272608, Validation Loss: 0.02946332097053528\n",
      "Part: 1/3, Epoch: 32/100, Total Epochs: 32, Train Loss: 0.0033689052797853947, Validation Loss: 0.02917361631989479\n",
      "Part: 1/3, Epoch: 33/100, Total Epochs: 33, Train Loss: 0.003301633056253195, Validation Loss: 0.028888916596770287\n",
      "Part: 1/3, Epoch: 34/100, Total Epochs: 34, Train Loss: 0.00323642254807055, Validation Loss: 0.028609473258256912\n",
      "Part: 1/3, Epoch: 35/100, Total Epochs: 35, Train Loss: 0.003173302626237273, Validation Loss: 0.028334397822618484\n",
      "Part: 1/3, Epoch: 36/100, Total Epochs: 36, Train Loss: 0.0031109731644392014, Validation Loss: 0.028060518205165863\n",
      "Part: 1/3, Epoch: 37/100, Total Epochs: 37, Train Loss: 0.0030492316000163555, Validation Loss: 0.027790021151304245\n",
      "Part: 1/3, Epoch: 38/100, Total Epochs: 38, Train Loss: 0.0029890474397689104, Validation Loss: 0.027523163706064224\n",
      "Part: 1/3, Epoch: 39/100, Total Epochs: 39, Train Loss: 0.002930551301687956, Validation Loss: 0.0272601917386055\n",
      "Part: 1/3, Epoch: 40/100, Total Epochs: 40, Train Loss: 0.0028737387619912624, Validation Loss: 0.027001257985830307\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_40\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_40\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 40\n",
      "Part: 1/3, Epoch: 41/100, Total Epochs: 41, Train Loss: 0.002818574896082282, Validation Loss: 0.026746509596705437\n",
      "Part: 1/3, Epoch: 42/100, Total Epochs: 42, Train Loss: 0.002765077166259289, Validation Loss: 0.02649606764316559\n",
      "Part: 1/3, Epoch: 43/100, Total Epochs: 43, Train Loss: 0.0027132395189255476, Validation Loss: 0.026250112801790237\n",
      "Part: 1/3, Epoch: 44/100, Total Epochs: 44, Train Loss: 0.0026630256325006485, Validation Loss: 0.026008596643805504\n",
      "Part: 1/3, Epoch: 45/100, Total Epochs: 45, Train Loss: 0.0026143959257751703, Validation Loss: 0.025771446526050568\n",
      "Part: 1/3, Epoch: 46/100, Total Epochs: 46, Train Loss: 0.0025673527270555496, Validation Loss: 0.025538643822073936\n",
      "Part: 1/3, Epoch: 47/100, Total Epochs: 47, Train Loss: 0.0025218194350600243, Validation Loss: 0.02531011961400509\n",
      "Part: 1/3, Epoch: 48/100, Total Epochs: 48, Train Loss: 0.0024777103681117296, Validation Loss: 0.025085803121328354\n",
      "Part: 1/3, Epoch: 49/100, Total Epochs: 49, Train Loss: 0.002435009926557541, Validation Loss: 0.02486572042107582\n",
      "Part: 1/3, Epoch: 50/100, Total Epochs: 50, Train Loss: 0.002393679693341255, Validation Loss: 0.024649830535054207\n",
      "Part: 1/3, Epoch: 51/100, Total Epochs: 51, Train Loss: 0.00235367682762444, Validation Loss: 0.02443796768784523\n",
      "Part: 1/3, Epoch: 52/100, Total Epochs: 52, Train Loss: 0.002314953599125147, Validation Loss: 0.024230413138866425\n",
      "Part: 1/3, Epoch: 53/100, Total Epochs: 53, Train Loss: 0.0022774729877710342, Validation Loss: 0.024026941508054733\n",
      "Part: 1/3, Epoch: 54/100, Total Epochs: 54, Train Loss: 0.002241160487756133, Validation Loss: 0.02382739633321762\n",
      "Part: 1/3, Epoch: 55/100, Total Epochs: 55, Train Loss: 0.0022060060873627663, Validation Loss: 0.023631751537322998\n",
      "Part: 1/3, Epoch: 56/100, Total Epochs: 56, Train Loss: 0.002171815373003483, Validation Loss: 0.023440329357981682\n",
      "Part: 1/3, Epoch: 57/100, Total Epochs: 57, Train Loss: 0.002138543641194701, Validation Loss: 0.02325320616364479\n",
      "Part: 1/3, Epoch: 58/100, Total Epochs: 58, Train Loss: 0.002106290776282549, Validation Loss: 0.02306975983083248\n",
      "Part: 1/3, Epoch: 59/100, Total Epochs: 59, Train Loss: 0.002074997639283538, Validation Loss: 0.022889986634254456\n",
      "Part: 1/3, Epoch: 60/100, Total Epochs: 60, Train Loss: 0.0020446034613996744, Validation Loss: 0.0227137953042984\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_60\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_60\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 60\n",
      "Part: 1/3, Epoch: 61/100, Total Epochs: 61, Train Loss: 0.002014986937865615, Validation Loss: 0.022541113197803497\n",
      "Part: 1/3, Epoch: 62/100, Total Epochs: 62, Train Loss: 0.001986251911148429, Validation Loss: 0.022371884435415268\n",
      "Part: 1/3, Epoch: 63/100, Total Epochs: 63, Train Loss: 0.0019583827815949917, Validation Loss: 0.022206071764230728\n",
      "Part: 1/3, Epoch: 64/100, Total Epochs: 64, Train Loss: 0.001931371632963419, Validation Loss: 0.02204360067844391\n",
      "Part: 1/3, Epoch: 65/100, Total Epochs: 65, Train Loss: 0.0019051835406571627, Validation Loss: 0.021884404122829437\n",
      "Part: 1/3, Epoch: 66/100, Total Epochs: 66, Train Loss: 0.0018797963857650757, Validation Loss: 0.02172842063009739\n",
      "Part: 1/3, Epoch: 67/100, Total Epochs: 67, Train Loss: 0.0018551747780293226, Validation Loss: 0.021575607359409332\n",
      "Part: 1/3, Epoch: 68/100, Total Epochs: 68, Train Loss: 0.0018312374595552683, Validation Loss: 0.021425899118185043\n",
      "Part: 1/3, Epoch: 69/100, Total Epochs: 69, Train Loss: 0.0018080211011692882, Validation Loss: 0.021279044449329376\n",
      "Part: 1/3, Epoch: 70/100, Total Epochs: 70, Train Loss: 0.0017855000915005803, Validation Loss: 0.02113499864935875\n",
      "Part: 1/3, Epoch: 71/100, Total Epochs: 71, Train Loss: 0.001763654756359756, Validation Loss: 0.020993342623114586\n",
      "Part: 1/3, Epoch: 72/100, Total Epochs: 72, Train Loss: 0.0017424518009647727, Validation Loss: 0.020854484289884567\n",
      "Part: 1/3, Epoch: 73/100, Total Epochs: 73, Train Loss: 0.001721840351819992, Validation Loss: 0.020718440413475037\n",
      "Part: 1/3, Epoch: 74/100, Total Epochs: 74, Train Loss: 0.001701762550510466, Validation Loss: 0.020585138350725174\n",
      "Part: 1/3, Epoch: 75/100, Total Epochs: 75, Train Loss: 0.0016822479665279388, Validation Loss: 0.02045449987053871\n",
      "Part: 1/3, Epoch: 76/100, Total Epochs: 76, Train Loss: 0.0016633057966828346, Validation Loss: 0.020326558500528336\n",
      "Part: 1/3, Epoch: 77/100, Total Epochs: 77, Train Loss: 0.0016449517570436, Validation Loss: 0.020201245322823524\n",
      "Part: 1/3, Epoch: 78/100, Total Epochs: 78, Train Loss: 0.0016270085470750928, Validation Loss: 0.02007841132581234\n",
      "Part: 1/3, Epoch: 79/100, Total Epochs: 79, Train Loss: 0.0016095081809908152, Validation Loss: 0.019957955926656723\n",
      "Part: 1/3, Epoch: 80/100, Total Epochs: 80, Train Loss: 0.0015924604376778007, Validation Loss: 0.01983991637825966\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_80\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_80\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 80\n",
      "Part: 1/3, Epoch: 81/100, Total Epochs: 81, Train Loss: 0.0015759286470711231, Validation Loss: 0.019724160432815552\n",
      "Part: 1/3, Epoch: 82/100, Total Epochs: 82, Train Loss: 0.001559909083880484, Validation Loss: 0.01961076259613037\n",
      "Part: 1/3, Epoch: 83/100, Total Epochs: 83, Train Loss: 0.0015442949952557683, Validation Loss: 0.019499588757753372\n",
      "Part: 1/3, Epoch: 84/100, Total Epochs: 84, Train Loss: 0.0015290742740035057, Validation Loss: 0.019390590488910675\n",
      "Part: 1/3, Epoch: 85/100, Total Epochs: 85, Train Loss: 0.00151416368316859, Validation Loss: 0.019283730536699295\n",
      "Part: 1/3, Epoch: 86/100, Total Epochs: 86, Train Loss: 0.0014995685778558254, Validation Loss: 0.019178949296474457\n",
      "Part: 1/3, Epoch: 87/100, Total Epochs: 87, Train Loss: 0.0014853390166535974, Validation Loss: 0.019076213240623474\n",
      "Part: 1/3, Epoch: 88/100, Total Epochs: 88, Train Loss: 0.0014714428689330816, Validation Loss: 0.01897546835243702\n",
      "Part: 1/3, Epoch: 89/100, Total Epochs: 89, Train Loss: 0.0014578524278476834, Validation Loss: 0.018876496702432632\n",
      "Part: 1/3, Epoch: 90/100, Total Epochs: 90, Train Loss: 0.0014445832930505276, Validation Loss: 0.0187793280929327\n",
      "Part: 1/3, Epoch: 91/100, Total Epochs: 91, Train Loss: 0.0014316309243440628, Validation Loss: 0.01868404448032379\n",
      "Part: 1/3, Epoch: 92/100, Total Epochs: 92, Train Loss: 0.0014189613284543157, Validation Loss: 0.01859060674905777\n",
      "Part: 1/3, Epoch: 93/100, Total Epochs: 93, Train Loss: 0.001406551105901599, Validation Loss: 0.018498975783586502\n",
      "Part: 1/3, Epoch: 94/100, Total Epochs: 94, Train Loss: 0.0013943668454885483, Validation Loss: 0.01840921863913536\n",
      "Part: 1/3, Epoch: 95/100, Total Epochs: 95, Train Loss: 0.0013824880588799715, Validation Loss: 0.018321163952350616\n",
      "Part: 1/3, Epoch: 96/100, Total Epochs: 96, Train Loss: 0.001370848622173071, Validation Loss: 0.0182344987988472\n",
      "Part: 1/3, Epoch: 97/100, Total Epochs: 97, Train Loss: 0.0013594604097306728, Validation Loss: 0.018149401992559433\n",
      "Part: 1/3, Epoch: 98/100, Total Epochs: 98, Train Loss: 0.0013482921058312058, Validation Loss: 0.01806587725877762\n",
      "Part: 1/3, Epoch: 99/100, Total Epochs: 99, Train Loss: 0.0013373303227126598, Validation Loss: 0.017983827739953995\n",
      "Part: 1/3, Epoch: 100/100, Total Epochs: 100, Train Loss: 0.0013265903107821941, Validation Loss: 0.01790320873260498\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 100\n",
      "Part: 2/3, Epoch: 1/100, Total Epochs: 101, Train Loss: 0.013353763148188591, Validation Loss: 0.01772676222026348\n",
      "Part: 2/3, Epoch: 2/100, Total Epochs: 102, Train Loss: 0.012671323493123055, Validation Loss: 0.01713068038225174\n",
      "Part: 2/3, Epoch: 3/100, Total Epochs: 103, Train Loss: 0.011828400194644928, Validation Loss: 0.016367066651582718\n",
      "Part: 2/3, Epoch: 4/100, Total Epochs: 104, Train Loss: 0.010962890461087227, Validation Loss: 0.015578964725136757\n",
      "Part: 2/3, Epoch: 5/100, Total Epochs: 105, Train Loss: 0.010139279067516327, Validation Loss: 0.014824514277279377\n",
      "Part: 2/3, Epoch: 6/100, Total Epochs: 106, Train Loss: 0.009388547390699387, Validation Loss: 0.01413235068321228\n",
      "Part: 2/3, Epoch: 7/100, Total Epochs: 107, Train Loss: 0.008715122938156128, Validation Loss: 0.013504101894795895\n",
      "Part: 2/3, Epoch: 8/100, Total Epochs: 108, Train Loss: 0.008112610317766666, Validation Loss: 0.012942327186465263\n",
      "Part: 2/3, Epoch: 9/100, Total Epochs: 109, Train Loss: 0.007582920603454113, Validation Loss: 0.012447074055671692\n",
      "Part: 2/3, Epoch: 10/100, Total Epochs: 110, Train Loss: 0.0071191079914569855, Validation Loss: 0.012012487277388573\n",
      "Part: 2/3, Epoch: 11/100, Total Epochs: 111, Train Loss: 0.006712253671139479, Validation Loss: 0.011631358414888382\n",
      "Part: 2/3, Epoch: 12/100, Total Epochs: 112, Train Loss: 0.0063543482683598995, Validation Loss: 0.011296150274574757\n",
      "Part: 2/3, Epoch: 13/100, Total Epochs: 113, Train Loss: 0.006038198713213205, Validation Loss: 0.011000331491231918\n",
      "Part: 2/3, Epoch: 14/100, Total Epochs: 114, Train Loss: 0.005758602172136307, Validation Loss: 0.010738961398601532\n",
      "Part: 2/3, Epoch: 15/100, Total Epochs: 115, Train Loss: 0.005509854294359684, Validation Loss: 0.01050640270113945\n",
      "Part: 2/3, Epoch: 16/100, Total Epochs: 116, Train Loss: 0.0052869077771902084, Validation Loss: 0.010297429747879505\n",
      "Part: 2/3, Epoch: 17/100, Total Epochs: 117, Train Loss: 0.0050857351161539555, Validation Loss: 0.01010874193161726\n",
      "Part: 2/3, Epoch: 18/100, Total Epochs: 118, Train Loss: 0.004902347922325134, Validation Loss: 0.009937173686921597\n",
      "Part: 2/3, Epoch: 19/100, Total Epochs: 119, Train Loss: 0.004734273999929428, Validation Loss: 0.009779899381101131\n",
      "Part: 2/3, Epoch: 20/100, Total Epochs: 120, Train Loss: 0.004579363390803337, Validation Loss: 0.009634891524910927\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_120\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_120\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 120\n",
      "Part: 2/3, Epoch: 21/100, Total Epochs: 121, Train Loss: 0.004435677081346512, Validation Loss: 0.009500372223556042\n",
      "Part: 2/3, Epoch: 22/100, Total Epochs: 122, Train Loss: 0.0043023452162742615, Validation Loss: 0.0093732550740242\n",
      "Part: 2/3, Epoch: 23/100, Total Epochs: 123, Train Loss: 0.004177817143499851, Validation Loss: 0.009251769632101059\n",
      "Part: 2/3, Epoch: 24/100, Total Epochs: 124, Train Loss: 0.004061070270836353, Validation Loss: 0.009137388318777084\n",
      "Part: 2/3, Epoch: 25/100, Total Epochs: 125, Train Loss: 0.003951219376176596, Validation Loss: 0.009029427543282509\n",
      "Part: 2/3, Epoch: 26/100, Total Epochs: 126, Train Loss: 0.003847045823931694, Validation Loss: 0.008927256800234318\n",
      "Part: 2/3, Epoch: 27/100, Total Epochs: 127, Train Loss: 0.0037454436533153057, Validation Loss: 0.008828433230519295\n",
      "Part: 2/3, Epoch: 28/100, Total Epochs: 128, Train Loss: 0.003648304846137762, Validation Loss: 0.008733288384974003\n",
      "Part: 2/3, Epoch: 29/100, Total Epochs: 129, Train Loss: 0.0035555206704884768, Validation Loss: 0.00864176731556654\n",
      "Part: 2/3, Epoch: 30/100, Total Epochs: 130, Train Loss: 0.003466920694336295, Validation Loss: 0.008553748019039631\n",
      "Part: 2/3, Epoch: 31/100, Total Epochs: 131, Train Loss: 0.0033822907134890556, Validation Loss: 0.008469006977975368\n",
      "Part: 2/3, Epoch: 32/100, Total Epochs: 132, Train Loss: 0.003301190212368965, Validation Loss: 0.008387299254536629\n",
      "Part: 2/3, Epoch: 33/100, Total Epochs: 133, Train Loss: 0.003223652485758066, Validation Loss: 0.00830867700278759\n",
      "Part: 2/3, Epoch: 34/100, Total Epochs: 134, Train Loss: 0.003149450523778796, Validation Loss: 0.008232749998569489\n",
      "Part: 2/3, Epoch: 35/100, Total Epochs: 135, Train Loss: 0.003078248118981719, Validation Loss: 0.008159434422850609\n",
      "Part: 2/3, Epoch: 36/100, Total Epochs: 136, Train Loss: 0.003009780542925, Validation Loss: 0.0080879433080554\n",
      "Part: 2/3, Epoch: 37/100, Total Epochs: 137, Train Loss: 0.0029433988966047764, Validation Loss: 0.008016526699066162\n",
      "Part: 2/3, Epoch: 38/100, Total Epochs: 138, Train Loss: 0.0028791455551981926, Validation Loss: 0.007946698926389217\n",
      "Part: 2/3, Epoch: 39/100, Total Epochs: 139, Train Loss: 0.002816994907334447, Validation Loss: 0.007877525873482227\n",
      "Part: 2/3, Epoch: 40/100, Total Epochs: 140, Train Loss: 0.0027568412479013205, Validation Loss: 0.007809611968696117\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_140\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_140\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 140\n",
      "Part: 2/3, Epoch: 41/100, Total Epochs: 141, Train Loss: 0.0026987972669303417, Validation Loss: 0.007743221707642078\n",
      "Part: 2/3, Epoch: 42/100, Total Epochs: 142, Train Loss: 0.0026429002173244953, Validation Loss: 0.00767858000472188\n",
      "Part: 2/3, Epoch: 43/100, Total Epochs: 143, Train Loss: 0.0025891007389873266, Validation Loss: 0.007615744136273861\n",
      "Part: 2/3, Epoch: 44/100, Total Epochs: 144, Train Loss: 0.0025376693811267614, Validation Loss: 0.007554503623396158\n",
      "Part: 2/3, Epoch: 45/100, Total Epochs: 145, Train Loss: 0.0024880114942789078, Validation Loss: 0.0074945781379938126\n",
      "Part: 2/3, Epoch: 46/100, Total Epochs: 146, Train Loss: 0.002440025331452489, Validation Loss: 0.007435700856149197\n",
      "Part: 2/3, Epoch: 47/100, Total Epochs: 147, Train Loss: 0.0023938165977597237, Validation Loss: 0.007378425449132919\n",
      "Part: 2/3, Epoch: 48/100, Total Epochs: 148, Train Loss: 0.002349426969885826, Validation Loss: 0.007323226425796747\n",
      "Part: 2/3, Epoch: 49/100, Total Epochs: 149, Train Loss: 0.002305423840880394, Validation Loss: 0.007268809713423252\n",
      "Part: 2/3, Epoch: 50/100, Total Epochs: 150, Train Loss: 0.0022622100077569485, Validation Loss: 0.007215061224997044\n",
      "Part: 2/3, Epoch: 51/100, Total Epochs: 151, Train Loss: 0.0022201435640454292, Validation Loss: 0.00716282706707716\n",
      "Part: 2/3, Epoch: 52/100, Total Epochs: 152, Train Loss: 0.0021789390593767166, Validation Loss: 0.0071116224862635136\n",
      "Part: 2/3, Epoch: 53/100, Total Epochs: 153, Train Loss: 0.002138867974281311, Validation Loss: 0.007061381358653307\n",
      "Part: 2/3, Epoch: 54/100, Total Epochs: 154, Train Loss: 0.002100112847983837, Validation Loss: 0.007012244313955307\n",
      "Part: 2/3, Epoch: 55/100, Total Epochs: 155, Train Loss: 0.002062773797661066, Validation Loss: 0.006964290514588356\n",
      "Part: 2/3, Epoch: 56/100, Total Epochs: 156, Train Loss: 0.0020272256806492805, Validation Loss: 0.006917138583958149\n",
      "Part: 2/3, Epoch: 57/100, Total Epochs: 157, Train Loss: 0.001993352547287941, Validation Loss: 0.006870729383081198\n",
      "Part: 2/3, Epoch: 58/100, Total Epochs: 158, Train Loss: 0.0019608289003372192, Validation Loss: 0.006825214251875877\n",
      "Part: 2/3, Epoch: 59/100, Total Epochs: 159, Train Loss: 0.0019296412356197834, Validation Loss: 0.006780725903809071\n",
      "Part: 2/3, Epoch: 60/100, Total Epochs: 160, Train Loss: 0.0018995137652382255, Validation Loss: 0.00673735560849309\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_160\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_160\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 160\n",
      "Part: 2/3, Epoch: 61/100, Total Epochs: 161, Train Loss: 0.0018705802503973246, Validation Loss: 0.006694989278912544\n",
      "Part: 2/3, Epoch: 62/100, Total Epochs: 162, Train Loss: 0.0018426491878926754, Validation Loss: 0.006653585471212864\n",
      "Part: 2/3, Epoch: 63/100, Total Epochs: 163, Train Loss: 0.0018157256999984384, Validation Loss: 0.006612027995288372\n",
      "Part: 2/3, Epoch: 64/100, Total Epochs: 164, Train Loss: 0.0017892179312184453, Validation Loss: 0.006570285186171532\n",
      "Part: 2/3, Epoch: 65/100, Total Epochs: 165, Train Loss: 0.0017633078387007117, Validation Loss: 0.006529497914016247\n",
      "Part: 2/3, Epoch: 66/100, Total Epochs: 166, Train Loss: 0.0017381059005856514, Validation Loss: 0.006489869672805071\n",
      "Part: 2/3, Epoch: 67/100, Total Epochs: 167, Train Loss: 0.0017136596143245697, Validation Loss: 0.006451298948377371\n",
      "Part: 2/3, Epoch: 68/100, Total Epochs: 168, Train Loss: 0.0016898097237572074, Validation Loss: 0.006413803901523352\n",
      "Part: 2/3, Epoch: 69/100, Total Epochs: 169, Train Loss: 0.001665420364588499, Validation Loss: 0.006376669742166996\n",
      "Part: 2/3, Epoch: 70/100, Total Epochs: 170, Train Loss: 0.0016408134251832962, Validation Loss: 0.006340425461530685\n",
      "Part: 2/3, Epoch: 71/100, Total Epochs: 171, Train Loss: 0.0016164693515747786, Validation Loss: 0.0063050673343241215\n",
      "Part: 2/3, Epoch: 72/100, Total Epochs: 172, Train Loss: 0.0015926273772493005, Validation Loss: 0.006270607467740774\n",
      "Part: 2/3, Epoch: 73/100, Total Epochs: 173, Train Loss: 0.00156941800378263, Validation Loss: 0.006237040739506483\n",
      "Part: 2/3, Epoch: 74/100, Total Epochs: 174, Train Loss: 0.0015469137579202652, Validation Loss: 0.006204324308782816\n",
      "Part: 2/3, Epoch: 75/100, Total Epochs: 175, Train Loss: 0.0015251713339239359, Validation Loss: 0.006172447465360165\n",
      "Part: 2/3, Epoch: 76/100, Total Epochs: 176, Train Loss: 0.0015041881706565619, Validation Loss: 0.006141623016446829\n",
      "Part: 2/3, Epoch: 77/100, Total Epochs: 177, Train Loss: 0.0014838599599897861, Validation Loss: 0.006112195551395416\n",
      "Part: 2/3, Epoch: 78/100, Total Epochs: 178, Train Loss: 0.0014647507341578603, Validation Loss: 0.006084599997848272\n",
      "Part: 2/3, Epoch: 79/100, Total Epochs: 179, Train Loss: 0.0014463129919022322, Validation Loss: 0.006057261489331722\n",
      "Part: 2/3, Epoch: 80/100, Total Epochs: 180, Train Loss: 0.001428529853001237, Validation Loss: 0.0060297343879938126\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_180\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_180\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 180\n",
      "Part: 2/3, Epoch: 81/100, Total Epochs: 181, Train Loss: 0.0014113974757492542, Validation Loss: 0.006002307403832674\n",
      "Part: 2/3, Epoch: 82/100, Total Epochs: 182, Train Loss: 0.001395010040141642, Validation Loss: 0.00597531720995903\n",
      "Part: 2/3, Epoch: 83/100, Total Epochs: 183, Train Loss: 0.0013791159726679325, Validation Loss: 0.005948605015873909\n",
      "Part: 2/3, Epoch: 84/100, Total Epochs: 184, Train Loss: 0.0013636737130582333, Validation Loss: 0.005922479555010796\n",
      "Part: 2/3, Epoch: 85/100, Total Epochs: 185, Train Loss: 0.0013485746458172798, Validation Loss: 0.005896946880966425\n",
      "Part: 2/3, Epoch: 86/100, Total Epochs: 186, Train Loss: 0.0013336159754544497, Validation Loss: 0.005872057750821114\n",
      "Part: 2/3, Epoch: 87/100, Total Epochs: 187, Train Loss: 0.0013190301833674312, Validation Loss: 0.005847787484526634\n",
      "Part: 2/3, Epoch: 88/100, Total Epochs: 188, Train Loss: 0.001304907607845962, Validation Loss: 0.005824119783937931\n",
      "Part: 2/3, Epoch: 89/100, Total Epochs: 189, Train Loss: 0.001291259890422225, Validation Loss: 0.005801044870167971\n",
      "Part: 2/3, Epoch: 90/100, Total Epochs: 190, Train Loss: 0.001278189942240715, Validation Loss: 0.005778477527201176\n",
      "Part: 2/3, Epoch: 91/100, Total Epochs: 191, Train Loss: 0.0012655226746574044, Validation Loss: 0.005756409838795662\n",
      "Part: 2/3, Epoch: 92/100, Total Epochs: 192, Train Loss: 0.0012531173415482044, Validation Loss: 0.005734850186854601\n",
      "Part: 2/3, Epoch: 93/100, Total Epochs: 193, Train Loss: 0.001241062069311738, Validation Loss: 0.0057138195261359215\n",
      "Part: 2/3, Epoch: 94/100, Total Epochs: 194, Train Loss: 0.0012293492909520864, Validation Loss: 0.005693297367542982\n",
      "Part: 2/3, Epoch: 95/100, Total Epochs: 195, Train Loss: 0.0012179738841950893, Validation Loss: 0.005673287436366081\n",
      "Part: 2/3, Epoch: 96/100, Total Epochs: 196, Train Loss: 0.0012070294469594955, Validation Loss: 0.005654043983668089\n",
      "Part: 2/3, Epoch: 97/100, Total Epochs: 197, Train Loss: 0.0011964128352701664, Validation Loss: 0.005635899491608143\n",
      "Part: 2/3, Epoch: 98/100, Total Epochs: 198, Train Loss: 0.0011861895909532905, Validation Loss: 0.005618513096123934\n",
      "Part: 2/3, Epoch: 99/100, Total Epochs: 199, Train Loss: 0.0011762750800698996, Validation Loss: 0.005601467564702034\n",
      "Part: 2/3, Epoch: 100/100, Total Epochs: 200, Train Loss: 0.001166636124253273, Validation Loss: 0.0055847978219389915\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_200\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_200\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 200\n",
      "Part: 3/3, Epoch: 1/100, Total Epochs: 201, Train Loss: 0.03591203689575195, Validation Loss: 0.005513753276318312\n",
      "Part: 3/3, Epoch: 2/100, Total Epochs: 202, Train Loss: 0.03461267799139023, Validation Loss: 0.0052139549516141415\n",
      "Part: 3/3, Epoch: 3/100, Total Epochs: 203, Train Loss: 0.033220842480659485, Validation Loss: 0.004848943091928959\n",
      "Part: 3/3, Epoch: 4/100, Total Epochs: 204, Train Loss: 0.03184672072529793, Validation Loss: 0.004480934701859951\n",
      "Part: 3/3, Epoch: 5/100, Total Epochs: 205, Train Loss: 0.0306354071944952, Validation Loss: 0.004136129282414913\n",
      "Part: 3/3, Epoch: 6/100, Total Epochs: 206, Train Loss: 0.029540836811065674, Validation Loss: 0.0038129205349832773\n",
      "Part: 3/3, Epoch: 7/100, Total Epochs: 207, Train Loss: 0.028579765930771828, Validation Loss: 0.003503674641251564\n",
      "Part: 3/3, Epoch: 8/100, Total Epochs: 208, Train Loss: 0.027707785367965698, Validation Loss: 0.00322196283377707\n",
      "Part: 3/3, Epoch: 9/100, Total Epochs: 209, Train Loss: 0.02687239646911621, Validation Loss: 0.002969451481476426\n",
      "Part: 3/3, Epoch: 10/100, Total Epochs: 210, Train Loss: 0.026082484051585197, Validation Loss: 0.0027452828362584114\n",
      "Part: 3/3, Epoch: 11/100, Total Epochs: 211, Train Loss: 0.0252530574798584, Validation Loss: 0.0025428005028516054\n",
      "Part: 3/3, Epoch: 12/100, Total Epochs: 212, Train Loss: 0.024390973150730133, Validation Loss: 0.0023576414678245783\n",
      "Part: 3/3, Epoch: 13/100, Total Epochs: 213, Train Loss: 0.023516183719038963, Validation Loss: 0.0021870851051062346\n",
      "Part: 3/3, Epoch: 14/100, Total Epochs: 214, Train Loss: 0.022642850875854492, Validation Loss: 0.0020370197016745806\n",
      "Part: 3/3, Epoch: 15/100, Total Epochs: 215, Train Loss: 0.0218332652002573, Validation Loss: 0.0019113663583993912\n",
      "Part: 3/3, Epoch: 16/100, Total Epochs: 216, Train Loss: 0.021072208881378174, Validation Loss: 0.0018033920787274837\n",
      "Part: 3/3, Epoch: 17/100, Total Epochs: 217, Train Loss: 0.02039431594312191, Validation Loss: 0.0017125518061220646\n",
      "Part: 3/3, Epoch: 18/100, Total Epochs: 218, Train Loss: 0.019817940890789032, Validation Loss: 0.0016344391042366624\n",
      "Part: 3/3, Epoch: 19/100, Total Epochs: 219, Train Loss: 0.01931171491742134, Validation Loss: 0.0015664222883060575\n",
      "Part: 3/3, Epoch: 20/100, Total Epochs: 220, Train Loss: 0.018875475972890854, Validation Loss: 0.0015052437083795667\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_220\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_220\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 220\n",
      "Part: 3/3, Epoch: 21/100, Total Epochs: 221, Train Loss: 0.018486224114894867, Validation Loss: 0.0014475317439064384\n",
      "Part: 3/3, Epoch: 22/100, Total Epochs: 222, Train Loss: 0.018128113821148872, Validation Loss: 0.0013943748781457543\n",
      "Part: 3/3, Epoch: 23/100, Total Epochs: 223, Train Loss: 0.017791839316487312, Validation Loss: 0.0013447798555716872\n",
      "Part: 3/3, Epoch: 24/100, Total Epochs: 224, Train Loss: 0.017448360100388527, Validation Loss: 0.0012989732204005122\n",
      "Part: 3/3, Epoch: 25/100, Total Epochs: 225, Train Loss: 0.01710383966565132, Validation Loss: 0.001257368945516646\n",
      "Part: 3/3, Epoch: 26/100, Total Epochs: 226, Train Loss: 0.016751592978835106, Validation Loss: 0.001218971679918468\n",
      "Part: 3/3, Epoch: 27/100, Total Epochs: 227, Train Loss: 0.016385601833462715, Validation Loss: 0.0011870089219883084\n",
      "Part: 3/3, Epoch: 28/100, Total Epochs: 228, Train Loss: 0.016005009412765503, Validation Loss: 0.0011633274843916297\n",
      "Part: 3/3, Epoch: 29/100, Total Epochs: 229, Train Loss: 0.01562979444861412, Validation Loss: 0.0011464867275208235\n",
      "Part: 3/3, Epoch: 30/100, Total Epochs: 230, Train Loss: 0.015243958681821823, Validation Loss: 0.0011347078252583742\n",
      "Part: 3/3, Epoch: 31/100, Total Epochs: 231, Train Loss: 0.014868306927382946, Validation Loss: 0.001126779243350029\n",
      "Part: 3/3, Epoch: 32/100, Total Epochs: 232, Train Loss: 0.014507723040878773, Validation Loss: 0.0011200851295143366\n",
      "Part: 3/3, Epoch: 33/100, Total Epochs: 233, Train Loss: 0.01414875965565443, Validation Loss: 0.001113489386625588\n",
      "Part: 3/3, Epoch: 34/100, Total Epochs: 234, Train Loss: 0.013815839774906635, Validation Loss: 0.0011050741886720061\n",
      "Part: 3/3, Epoch: 35/100, Total Epochs: 235, Train Loss: 0.013474316336214542, Validation Loss: 0.0010944497771561146\n",
      "Part: 3/3, Epoch: 36/100, Total Epochs: 236, Train Loss: 0.013174459338188171, Validation Loss: 0.001081807422451675\n",
      "Part: 3/3, Epoch: 37/100, Total Epochs: 237, Train Loss: 0.012874125503003597, Validation Loss: 0.0010670229094102979\n",
      "Part: 3/3, Epoch: 38/100, Total Epochs: 238, Train Loss: 0.012584651820361614, Validation Loss: 0.001050440245307982\n",
      "Part: 3/3, Epoch: 39/100, Total Epochs: 239, Train Loss: 0.012322665192186832, Validation Loss: 0.0010332923848181963\n",
      "Part: 3/3, Epoch: 40/100, Total Epochs: 240, Train Loss: 0.012065171264111996, Validation Loss: 0.0010160946985706687\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_240\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_240\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 240\n",
      "Part: 3/3, Epoch: 41/100, Total Epochs: 241, Train Loss: 0.011832788586616516, Validation Loss: 0.0009988200617954135\n",
      "Part: 3/3, Epoch: 42/100, Total Epochs: 242, Train Loss: 0.011609233915805817, Validation Loss: 0.0009817380923777819\n",
      "Part: 3/3, Epoch: 43/100, Total Epochs: 243, Train Loss: 0.011390562169253826, Validation Loss: 0.0009627703693695366\n",
      "Part: 3/3, Epoch: 44/100, Total Epochs: 244, Train Loss: 0.01119121816009283, Validation Loss: 0.0009435890824533999\n",
      "Part: 3/3, Epoch: 45/100, Total Epochs: 245, Train Loss: 0.01099205482751131, Validation Loss: 0.0009254871401935816\n",
      "Part: 3/3, Epoch: 46/100, Total Epochs: 246, Train Loss: 0.010803836397826672, Validation Loss: 0.0009074627305381\n",
      "Part: 3/3, Epoch: 47/100, Total Epochs: 247, Train Loss: 0.01062180008739233, Validation Loss: 0.0008898593951016665\n",
      "Part: 3/3, Epoch: 48/100, Total Epochs: 248, Train Loss: 0.010447925888001919, Validation Loss: 0.0008725368534214795\n",
      "Part: 3/3, Epoch: 49/100, Total Epochs: 249, Train Loss: 0.010273999534547329, Validation Loss: 0.0008554481901228428\n",
      "Part: 3/3, Epoch: 50/100, Total Epochs: 250, Train Loss: 0.010113400407135487, Validation Loss: 0.0008389937574975193\n",
      "Part: 3/3, Epoch: 51/100, Total Epochs: 251, Train Loss: 0.009946589358150959, Validation Loss: 0.0008230365347117186\n",
      "Part: 3/3, Epoch: 52/100, Total Epochs: 252, Train Loss: 0.009780732914805412, Validation Loss: 0.0008072262280620635\n",
      "Part: 3/3, Epoch: 53/100, Total Epochs: 253, Train Loss: 0.00962489377707243, Validation Loss: 0.0007913068984635174\n",
      "Part: 3/3, Epoch: 54/100, Total Epochs: 254, Train Loss: 0.009445512667298317, Validation Loss: 0.0007751998491585255\n",
      "Part: 3/3, Epoch: 55/100, Total Epochs: 255, Train Loss: 0.009266982786357403, Validation Loss: 0.0007590235327370465\n",
      "Part: 3/3, Epoch: 56/100, Total Epochs: 256, Train Loss: 0.009081444703042507, Validation Loss: 0.0007432635757140815\n",
      "Part: 3/3, Epoch: 57/100, Total Epochs: 257, Train Loss: 0.008896893821656704, Validation Loss: 0.0007279151468537748\n",
      "Part: 3/3, Epoch: 58/100, Total Epochs: 258, Train Loss: 0.008712951093912125, Validation Loss: 0.0007130324374884367\n",
      "Part: 3/3, Epoch: 59/100, Total Epochs: 259, Train Loss: 0.008519885130226612, Validation Loss: 0.0006992388516664505\n",
      "Part: 3/3, Epoch: 60/100, Total Epochs: 260, Train Loss: 0.008327195420861244, Validation Loss: 0.0006867442862130702\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_260\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_260\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 260\n",
      "Part: 3/3, Epoch: 61/100, Total Epochs: 261, Train Loss: 0.00813241209834814, Validation Loss: 0.0006752110202796757\n",
      "Part: 3/3, Epoch: 62/100, Total Epochs: 262, Train Loss: 0.007933969609439373, Validation Loss: 0.0006644767126999795\n",
      "Part: 3/3, Epoch: 63/100, Total Epochs: 263, Train Loss: 0.00773830758407712, Validation Loss: 0.0006548271630890667\n",
      "Part: 3/3, Epoch: 64/100, Total Epochs: 264, Train Loss: 0.007544511463493109, Validation Loss: 0.0006465289043262601\n",
      "Part: 3/3, Epoch: 65/100, Total Epochs: 265, Train Loss: 0.007347773760557175, Validation Loss: 0.0006396076059900224\n",
      "Part: 3/3, Epoch: 66/100, Total Epochs: 266, Train Loss: 0.007152825128287077, Validation Loss: 0.0006335482466965914\n",
      "Part: 3/3, Epoch: 67/100, Total Epochs: 267, Train Loss: 0.006958877667784691, Validation Loss: 0.0006281621172092855\n",
      "Part: 3/3, Epoch: 68/100, Total Epochs: 268, Train Loss: 0.006773448083549738, Validation Loss: 0.0006234869360923767\n",
      "Part: 3/3, Epoch: 69/100, Total Epochs: 269, Train Loss: 0.0065932669676840305, Validation Loss: 0.0006195557652972639\n",
      "Part: 3/3, Epoch: 70/100, Total Epochs: 270, Train Loss: 0.006415667477995157, Validation Loss: 0.0006165571394376457\n",
      "Part: 3/3, Epoch: 71/100, Total Epochs: 271, Train Loss: 0.006250400096178055, Validation Loss: 0.0006144806975498796\n",
      "Part: 3/3, Epoch: 72/100, Total Epochs: 272, Train Loss: 0.006103869061917067, Validation Loss: 0.0006127162487246096\n",
      "Part: 3/3, Epoch: 73/100, Total Epochs: 273, Train Loss: 0.005967376288026571, Validation Loss: 0.0006113094859756529\n",
      "Part: 3/3, Epoch: 74/100, Total Epochs: 274, Train Loss: 0.005847841966897249, Validation Loss: 0.0006098836311139166\n",
      "Part: 3/3, Epoch: 75/100, Total Epochs: 275, Train Loss: 0.005738594103604555, Validation Loss: 0.0006082970066927373\n",
      "Part: 3/3, Epoch: 76/100, Total Epochs: 276, Train Loss: 0.0056393821723759174, Validation Loss: 0.0006065827910788357\n",
      "Part: 3/3, Epoch: 77/100, Total Epochs: 277, Train Loss: 0.005547559354454279, Validation Loss: 0.0006046476191841066\n",
      "Part: 3/3, Epoch: 78/100, Total Epochs: 278, Train Loss: 0.005458671133965254, Validation Loss: 0.0006026224000379443\n",
      "Part: 3/3, Epoch: 79/100, Total Epochs: 279, Train Loss: 0.005370518192648888, Validation Loss: 0.0006010085926391184\n",
      "Part: 3/3, Epoch: 80/100, Total Epochs: 280, Train Loss: 0.005288174841552973, Validation Loss: 0.0005994658567942679\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_280\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_280\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 280\n",
      "Part: 3/3, Epoch: 81/100, Total Epochs: 281, Train Loss: 0.0052096787840127945, Validation Loss: 0.0005982047296129167\n",
      "Part: 3/3, Epoch: 82/100, Total Epochs: 282, Train Loss: 0.005137139465659857, Validation Loss: 0.0005969933117739856\n",
      "Part: 3/3, Epoch: 83/100, Total Epochs: 283, Train Loss: 0.005066392477601767, Validation Loss: 0.0005957113462500274\n",
      "Part: 3/3, Epoch: 84/100, Total Epochs: 284, Train Loss: 0.004999719560146332, Validation Loss: 0.0005943572032265365\n",
      "Part: 3/3, Epoch: 85/100, Total Epochs: 285, Train Loss: 0.004934166092425585, Validation Loss: 0.0005929343751631677\n",
      "Part: 3/3, Epoch: 86/100, Total Epochs: 286, Train Loss: 0.004868768155574799, Validation Loss: 0.0005914921057410538\n",
      "Part: 3/3, Epoch: 87/100, Total Epochs: 287, Train Loss: 0.004806416109204292, Validation Loss: 0.0005901168333366513\n",
      "Part: 3/3, Epoch: 88/100, Total Epochs: 288, Train Loss: 0.004741871263831854, Validation Loss: 0.0005889813764952123\n",
      "Part: 3/3, Epoch: 89/100, Total Epochs: 289, Train Loss: 0.00468149408698082, Validation Loss: 0.0005878245574422181\n",
      "Part: 3/3, Epoch: 90/100, Total Epochs: 290, Train Loss: 0.004621259868144989, Validation Loss: 0.0005866910214535892\n",
      "Part: 3/3, Epoch: 91/100, Total Epochs: 291, Train Loss: 0.0045631518587470055, Validation Loss: 0.0005855316412635148\n",
      "Part: 3/3, Epoch: 92/100, Total Epochs: 292, Train Loss: 0.0045075565576553345, Validation Loss: 0.0005843644612468779\n",
      "Part: 3/3, Epoch: 93/100, Total Epochs: 293, Train Loss: 0.004450343083590269, Validation Loss: 0.0005833885516040027\n",
      "Part: 3/3, Epoch: 94/100, Total Epochs: 294, Train Loss: 0.004396175965666771, Validation Loss: 0.0005823936662636697\n",
      "Part: 3/3, Epoch: 95/100, Total Epochs: 295, Train Loss: 0.0043419343419373035, Validation Loss: 0.0005813752650283277\n",
      "Part: 3/3, Epoch: 96/100, Total Epochs: 296, Train Loss: 0.004288815427571535, Validation Loss: 0.0005803119856864214\n",
      "Part: 3/3, Epoch: 97/100, Total Epochs: 297, Train Loss: 0.004236206877976656, Validation Loss: 0.0005792300216853619\n",
      "Part: 3/3, Epoch: 98/100, Total Epochs: 298, Train Loss: 0.004193140659481287, Validation Loss: 0.0005783519591204822\n",
      "Part: 3/3, Epoch: 99/100, Total Epochs: 299, Train Loss: 0.004152728710323572, Validation Loss: 0.0005768462433479726\n",
      "Part: 3/3, Epoch: 100/100, Total Epochs: 300, Train Loss: 0.004112511873245239, Validation Loss: 0.0005746372044086456\n",
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_300\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\model_epoch_300\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 300\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "num_parts = 3\n",
    "part_size = len(df_sorted) // num_parts\n",
    "\n",
    "total_epochs_elapsed = 0  # Counter for total number of epochs elapsed\n",
    "\n",
    "# Lists to store the mean train and validation losses for each epoch across all parts\n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "\n",
    "for part in range(num_parts):\n",
    "    # Determine the dataset subset for the current part\n",
    "    end_idx = (part + 1) * part_size\n",
    "    X_subset, y_subset = prepare_data(df_sorted.iloc[:end_idx])\n",
    "\n",
    "    # Convert X_subset and y_subset to a single numpy array\n",
    "    X_subset = np.array(X_subset)\n",
    "    X_subset = [X_subset, y_subset]\n",
    "    y_subset = np.array(y_subset)\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_losses_per_epoch = []\n",
    "        val_losses_per_epoch = []\n",
    "\n",
    "        for i in range(0, len(X_subset[0]), BATCH_SIZE):\n",
    "            # print('len of X_subset[0][i:i+BATCH_SIZE]: ', len(X_subset[0][i:i+BATCH_SIZE]))\n",
    "            X_batch = [X_subset[0][i:i+BATCH_SIZE], X_subset[1][i:i+BATCH_SIZE]]\n",
    "            y_batch = y_subset[i:i+BATCH_SIZE]\n",
    "\n",
    "            # Training and validation steps remain unchanged\n",
    "            train_loss = train_step(X_batch, y_batch)\n",
    "            val_loss = validate_step(X_test, y_test)\n",
    "            train_losses_per_epoch.append(train_loss)\n",
    "            val_losses_per_epoch.append(val_loss)\n",
    "\n",
    "        mean_train_loss = np.mean(train_losses_per_epoch)\n",
    "        mean_val_loss = np.mean(val_losses_per_epoch)\n",
    "\n",
    "        # Store the mean losses for this epoch\n",
    "        all_train_losses.append(mean_train_loss)\n",
    "        all_val_losses.append(mean_val_loss)\n",
    "\n",
    "        total_epochs_elapsed += 1\n",
    "        print(f\"Part: {part+1}/{num_parts}, Epoch: {epoch+1}/{EPOCHS}, Total Epochs: {total_epochs_elapsed}, Train Loss: {mean_train_loss}, Validation Loss: {mean_val_loss}\")\n",
    "\n",
    "        if total_epochs_elapsed % 20 == 0:\n",
    "          model_path = os.path.join(model_save_dir, f\"model_epoch_{total_epochs_elapsed}\")\n",
    "          weights_path = os.path.join(model_save_dir, f\"weights_epoch_{total_epochs_elapsed}\")\n",
    "          tf.saved_model.save(model, model_path)\n",
    "          model.save_weights(weights_path)\n",
    "          \n",
    "          print(f\"Model and weights saved at epoch {total_epochs_elapsed}\")\n",
    "            \n",
    "          # Convert the recorded losses into a DataFrame\n",
    "          loss_df = pd.DataFrame({\n",
    "          'Epoch': list(range(1, len(all_train_losses) + 1)),\n",
    "          'Training_Loss': all_train_losses,\n",
    "          'Validation_Loss': all_val_losses\n",
    "           })\n",
    "\n",
    "          # Save the DataFrame to a CSV file\n",
    "          loss_df.to_csv(f'losses_{total_epochs_elapsed}.csv', index=False)  \n",
    "          \n",
    "          print(f\"Losses saved at epoch {total_epochs_elapsed}\")\n",
    "\n",
    "\n",
    "\n",
    "        if mean_train_loss <= 1e-6 or mean_val_loss <= 1e-6:\n",
    "            print(f\"Train Loss: {mean_train_loss} <= 1e-6, skipping to next stage of training\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "pcaEGqWGvJVE",
    "outputId": "cbda9378-502b-4ba6-d2c4-15ea13b6d7e3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1987622b305>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./checkpoints/my_checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozjhzlLFJc9j"
   },
   "outputs": [],
   "source": [
    "# model.save('./saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtLX_vklvPwH"
   },
   "outputs": [],
   "source": [
    "# model.load_weights('./saved_models/weights_epoch_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "RZbr3DldMg5L",
    "outputId": "deb8cbea-ee7d-4834-cc73-8de9138f0996",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(r\"C:\\Users\\ULTIMATEWOWEE\\Documents\\ML4GST\\saved_models\\model_epoch_160\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "aL6iMAOhH2nj",
    "outputId": "31d27df0-8b1e-4084-cd8b-c30e48a9a5e6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training and validation losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(all_train_losses, label='Training Loss')\n",
    "plt.plot(all_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0vf6jwkNtYD"
   },
   "outputs": [],
   "source": [
    "# Convert the recorded losses into a DataFrame\n",
    "loss_df = pd.DataFrame({\n",
    "    'Epoch': list(range(1, len(all_train_losses) + 1)),\n",
    "    'Training_Loss': all_train_losses,\n",
    "    'Validation_Loss': all_val_losses\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "loss_df.to_csv('losses.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Vd-mE6MJH48G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to sample part of the training data and evaluate model's performance\n",
    "def sample_and_evaluate(num_samples=20):\n",
    "    indices = np.random.choice(len(X_train[0]), size=num_samples, replace=False)\n",
    "    # indices = [i for i in range(10)]\n",
    "    sampled_X = [tf.cast(X_train[0][indices], dtype=tf.float32), tf.cast(X_train[1][indices], dtype=tf.float32)]\n",
    "    sampled_y = tf.cast(y_train[indices], dtype=tf.float32)\n",
    "    loss = validate_step(sampled_X, sampled_y, print_results = True)\n",
    "    print(f\"Loss on sampled data: {loss.numpy()}\")\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUOTaXO3Mhvq",
    "outputId": "541c2f4a-8e69-48e8-bfc9-a83471375282",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aurMt4AwNa40",
    "outputId": "550fcb81-85ed-40a6-fd52-de67b6154c83",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_errors:  [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.05686548], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.07216448], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.       , 0.2193803], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.16778213], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.23472401], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.10291527], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.13007769], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.      , 0.013388], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.07944658], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.10619263], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.       , 0.0976921], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.       , 0.0861585], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.11786254], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.15170997], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.15934655], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.03017879], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.12843944], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.09629727], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.18419944], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.        , 0.17649446], dtype=float32)>]\n",
      "Loss on sampled data: 0.005803531501442194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0058035315"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCP-Ov4QcTyl",
    "outputId": "82feba0f-61ce-4c1e-a2ab-e6ca7c2d3d37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=272>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntIlL0UZeYVi",
    "outputId": "8623848e-72c1-4ce1-dd79-7db74a79d2bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current label:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70710677, 0.        , 0.        , 0.70710677], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_gate(np.array([1/np.sqrt(2), 0, 0, 1/np.sqrt(2)], dtype=np.float32), 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jw0N66NJk3IN"
   },
   "outputs": [],
   "source": [
    "test_vector = np.array(\n",
    "    [[ 0.70710677],\n",
    "     [-0.7064972 ],\n",
    "     [ 0.        ],\n",
    "     [-0.02935636]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp_bRrqOlnbm",
    "outputId": "b2cfafa3-bc67-4983-d253-52fa87ddaeb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LacrNsyblsfq",
    "outputId": "a81f37b0-73b8-4afb-b3d7-e897e6889fe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(test_vector).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmMaS4Crkokb",
    "outputId": "15ccd2cd-df57-40f9-b457-a5828f2f5e9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.99999994>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_probabilities(tf.constant([1, 0, 0, 1], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTnDDEUNkbg-",
    "outputId": "a2706368-ea03-42a4-d950-faad34fa70b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99999994>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_probabilities(tf.constant([1, 0, 0, -1], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASCr3ie5SjJN"
   },
   "outputs": [],
   "source": [
    "# for i in range (tf.shape(X_train[:1])[0]):\n",
    "#   single_sequence = tf.gather(X_train, i, axis=0)\n",
    "#   print('single_sequence: ', single_sequence)\n",
    "#   final_state = apply_gate_sequence(single_sequence)\n",
    "#   print('final_state: ', final_state)\n",
    "#   probabilities = compute_probabilities(final_state)\n",
    "#   print('probabilities: ',probabilities )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bF4T9A-dOFuD",
    "outputId": "492d9a19-85de-4169-f308-73d24b015811"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EpcfNO0PMaL"
   },
   "outputs": [],
   "source": [
    "debug = tf.convert_to_tensor([[1, 0, 0, 0], [0, tf.math.cos(0.5), 0, tf.math.sin(0.5)],\n",
    "                           [0, 0, 1, 0], [0, -tf.math.sin(0.5), 0, tf.math.cos(0.5)]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNKTrgdkRHhi",
    "outputId": "7f3f7c76-53de-476b-c10c-9999a25d3189"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.87758255,  0.        ,  0.47942555],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        , -0.47942555,  0.        ,  0.87758255]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
